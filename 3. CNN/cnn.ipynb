{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlEFYW-AW1YX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFt9-kqWEpE",
        "outputId": "687f9e93-1ced-4652-af34-14213ed31380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "'''mnist = fetch_openml('mnist_784', version=1)\n",
        "X = mnist['data']\n",
        "y = mnist['target']'''\n",
        "\n",
        "mnist_data = np.load('/content/drive/MyDrive/2l/dataset.npz')\n",
        "images = mnist_data['images']\n",
        "labels = mnist_data['labels']\n",
        "\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(images, labels, test_size=0.1)\n",
        "\n",
        "X_train_1 = X_train_1.astype(np.float32)\n",
        "X_test_1 = X_test_1.astype(np.float32)\n",
        "y_train_1 = y_train_1.astype(np.long)\n",
        "y_test_1 = y_test_1.astype(np.long)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIlWdoxzW3FK",
        "outputId": "45d9d1a5-a0a7-400e-abd0-7e34b82c5a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3e46d634084f>:17: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_train_1 = y_train_1.astype(np.long)\n",
            "<ipython-input-3-3e46d634084f>:18: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_test_1 = y_test_1.astype(np.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_test_1, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6t7sQXeB5j1",
        "outputId": "0b0001f1-7e29-4b06-95c4-4318dd5dfb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 44, 1: 33, 2: 31, 3: 32, 4: 43, 5: 29, 6: 37, 7: 53, 8: 41, 9: 45}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert X_train to a PyTorch tensor.\n",
        "X_train = torch.from_numpy(X_train_1)\n",
        "# Permute the dimensions from [n, 25, 25, 3] to [n, 3, 25, 25].\n",
        "X_train = X_train.permute(0, 3, 1, 2)\n",
        "\n",
        "\n",
        "# Convert X_test to a PyTorch tensor.\n",
        "X_test = torch.from_numpy(X_test_1)\n",
        "# Permute the dimensions from [n, 25, 25, 3] to [n, 3, 25, 25].\n",
        "X_test = X_test.permute(0, 3, 1, 2)\n",
        "\n",
        "\n",
        "\n",
        "# Convert y_train to a PyTorch tensor\n",
        "y_train = torch.from_numpy(y_train_1)\n",
        "\n",
        "# Convert y_test to a PyTorch tensor\n",
        "y_test = torch.from_numpy(y_test_1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qSTNYcEFf2tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "udhV1CICbhma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX7t1K3efTVj",
        "outputId": "43374e46-7081-4fe3-e07b-e03b6088a434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3490, 3, 25, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Số classes trong tập MNIST\n",
        "num_classes = 10\n",
        "\n",
        "# Số epoch\n",
        "epochs = 10\n",
        "\n",
        "# Các tham số cần thiết trong quá trình training\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "display_step = 10\n",
        "\n",
        "# Model path\n",
        "checkpoint = 'model.pth'\n",
        "\n",
        "# device: cuda\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uE0ZZYWYufE",
        "outputId": "a22ccfbb-5ce3-4109-bfe8-7377cd888719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.8)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=9*9*64, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### START CODE HEAR ≈ 18 lines\n",
        "        ## 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        ### END CODE HERE\n",
        "        return x"
      ],
      "metadata": {
        "id": "7CzEhWMEXI9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model vào GPU\n",
        "model = Net().to(device)\n",
        "summary(model, (3, 25, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX8DtgLlXLN0",
        "outputId": "464e46f3-73d1-4129-9906-9f6843a6a8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 23, 23]             896\n",
            "              ReLU-2           [-1, 32, 23, 23]               0\n",
            "            Conv2d-3           [-1, 64, 21, 21]          18,496\n",
            "              ReLU-4           [-1, 64, 21, 21]               0\n",
            "            Conv2d-5           [-1, 64, 19, 19]          36,928\n",
            "              ReLU-6           [-1, 64, 19, 19]               0\n",
            "         MaxPool2d-7             [-1, 64, 9, 9]               0\n",
            "           Dropout-8             [-1, 64, 9, 9]               0\n",
            "           Flatten-9                 [-1, 5184]               0\n",
            "           Linear-10                  [-1, 128]         663,680\n",
            "             ReLU-11                  [-1, 128]               0\n",
            "           Linear-12                   [-1, 64]           8,256\n",
            "             ReLU-13                   [-1, 64]               0\n",
            "           Linear-14                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 728,906\n",
            "Trainable params: 728,906\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.16\n",
            "Params size (MB): 2.78\n",
            "Estimated Total Size (MB): 3.95\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropy\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Adam Optimizer set params=model.parameters(), lr=learning_rate\n",
        "best_val_loss = 999\n",
        "\n",
        "# Loop for each epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # Quá trình training\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Load dữ liệu vào GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Clear gradients cho mỗi batch\n",
        "        optimizer.zero_grad() # zero grad\n",
        "        output = model(data)\n",
        "\n",
        "        # Backpropagation, tính gradients\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward() #backward\n",
        "\n",
        "        # Apply gradients để update lại tham số\n",
        "        optimizer.step()\n",
        "        if batch_idx % display_step == 0:\n",
        "            print('Train Epoch {}: [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "    # Quá trình testing\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Set no grad cho quá trình testing\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # Load dữ liệu vào GPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            output = F.log_softmax(output,dim=1) # sử dụng hàm log_sotmax của pytorch để tính xác suất cho output, dim = 1\n",
        "            test_loss += criterion(output, target)\n",
        "            pred = output.argmax(dim = 1, keepdim = True) # Sử dụng hàm argmax để lấy predicted label, chú ý keepdim=True\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    if test_loss < best_val_loss:\n",
        "      best_val_loss = test_loss\n",
        "      torch.save(model.state_dict(), checkpoint)  # Lưu model path\n",
        "      print(\"***********    TEST_ACC = {:.2f}%    ***********\".format(correct/100))"
      ],
      "metadata": {
        "id": "QHm6WgrdZYUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb133ff0-1fa1-47ad-d8eb-bf655482b83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch 1: [0/3490 (0%)]\tTrain Loss: 6.553298\n",
            "Train Epoch 1: [320/3490 (9%)]\tTrain Loss: 2.306679\n",
            "Train Epoch 1: [640/3490 (18%)]\tTrain Loss: 2.311445\n",
            "Train Epoch 1: [960/3490 (27%)]\tTrain Loss: 2.226202\n",
            "Train Epoch 1: [1280/3490 (36%)]\tTrain Loss: 2.223166\n",
            "Train Epoch 1: [1600/3490 (45%)]\tTrain Loss: 2.230277\n",
            "Train Epoch 1: [1920/3490 (55%)]\tTrain Loss: 2.154254\n",
            "Train Epoch 1: [2240/3490 (64%)]\tTrain Loss: 1.810906\n",
            "Train Epoch 1: [2560/3490 (73%)]\tTrain Loss: 1.582484\n",
            "Train Epoch 1: [2880/3490 (82%)]\tTrain Loss: 1.810410\n",
            "Train Epoch 1: [3200/3490 (91%)]\tTrain Loss: 1.700886\n",
            "***********    TEST_ACC = 2.11%    ***********\n",
            "Train Epoch 2: [0/3490 (0%)]\tTrain Loss: 1.573705\n",
            "Train Epoch 2: [320/3490 (9%)]\tTrain Loss: 1.034598\n",
            "Train Epoch 2: [640/3490 (18%)]\tTrain Loss: 1.595805\n",
            "Train Epoch 2: [960/3490 (27%)]\tTrain Loss: 1.387930\n",
            "Train Epoch 2: [1280/3490 (36%)]\tTrain Loss: 1.601866\n",
            "Train Epoch 2: [1600/3490 (45%)]\tTrain Loss: 1.095042\n",
            "Train Epoch 2: [1920/3490 (55%)]\tTrain Loss: 1.096121\n",
            "Train Epoch 2: [2240/3490 (64%)]\tTrain Loss: 1.451956\n",
            "Train Epoch 2: [2560/3490 (73%)]\tTrain Loss: 0.929828\n",
            "Train Epoch 2: [2880/3490 (82%)]\tTrain Loss: 0.841447\n",
            "Train Epoch 2: [3200/3490 (91%)]\tTrain Loss: 1.049428\n",
            "***********    TEST_ACC = 3.23%    ***********\n",
            "Train Epoch 3: [0/3490 (0%)]\tTrain Loss: 0.923818\n",
            "Train Epoch 3: [320/3490 (9%)]\tTrain Loss: 1.003900\n",
            "Train Epoch 3: [640/3490 (18%)]\tTrain Loss: 0.474534\n",
            "Train Epoch 3: [960/3490 (27%)]\tTrain Loss: 0.769554\n",
            "Train Epoch 3: [1280/3490 (36%)]\tTrain Loss: 0.752429\n",
            "Train Epoch 3: [1600/3490 (45%)]\tTrain Loss: 0.401385\n",
            "Train Epoch 3: [1920/3490 (55%)]\tTrain Loss: 0.426937\n",
            "Train Epoch 3: [2240/3490 (64%)]\tTrain Loss: 0.656432\n",
            "Train Epoch 3: [2560/3490 (73%)]\tTrain Loss: 0.575057\n",
            "Train Epoch 3: [2880/3490 (82%)]\tTrain Loss: 0.695433\n",
            "Train Epoch 3: [3200/3490 (91%)]\tTrain Loss: 0.795537\n",
            "***********    TEST_ACC = 3.49%    ***********\n",
            "Train Epoch 4: [0/3490 (0%)]\tTrain Loss: 0.517546\n",
            "Train Epoch 4: [320/3490 (9%)]\tTrain Loss: 0.434581\n",
            "Train Epoch 4: [640/3490 (18%)]\tTrain Loss: 0.492919\n",
            "Train Epoch 4: [960/3490 (27%)]\tTrain Loss: 0.543622\n",
            "Train Epoch 4: [1280/3490 (36%)]\tTrain Loss: 0.583943\n",
            "Train Epoch 4: [1600/3490 (45%)]\tTrain Loss: 0.548013\n",
            "Train Epoch 4: [1920/3490 (55%)]\tTrain Loss: 0.513764\n",
            "Train Epoch 4: [2240/3490 (64%)]\tTrain Loss: 0.544645\n",
            "Train Epoch 4: [2560/3490 (73%)]\tTrain Loss: 0.391641\n",
            "Train Epoch 4: [2880/3490 (82%)]\tTrain Loss: 0.530909\n",
            "Train Epoch 4: [3200/3490 (91%)]\tTrain Loss: 0.387253\n",
            "***********    TEST_ACC = 3.57%    ***********\n",
            "Train Epoch 5: [0/3490 (0%)]\tTrain Loss: 0.274142\n",
            "Train Epoch 5: [320/3490 (9%)]\tTrain Loss: 0.144758\n",
            "Train Epoch 5: [640/3490 (18%)]\tTrain Loss: 0.115608\n",
            "Train Epoch 5: [960/3490 (27%)]\tTrain Loss: 0.469880\n",
            "Train Epoch 5: [1280/3490 (36%)]\tTrain Loss: 0.188037\n",
            "Train Epoch 5: [1600/3490 (45%)]\tTrain Loss: 0.440474\n",
            "Train Epoch 5: [1920/3490 (55%)]\tTrain Loss: 0.216814\n",
            "Train Epoch 5: [2240/3490 (64%)]\tTrain Loss: 0.307602\n",
            "Train Epoch 5: [2560/3490 (73%)]\tTrain Loss: 0.684764\n",
            "Train Epoch 5: [2880/3490 (82%)]\tTrain Loss: 0.191077\n",
            "Train Epoch 5: [3200/3490 (91%)]\tTrain Loss: 0.264820\n",
            "***********    TEST_ACC = 3.59%    ***********\n",
            "Train Epoch 6: [0/3490 (0%)]\tTrain Loss: 0.207195\n",
            "Train Epoch 6: [320/3490 (9%)]\tTrain Loss: 0.453946\n",
            "Train Epoch 6: [640/3490 (18%)]\tTrain Loss: 0.204476\n",
            "Train Epoch 6: [960/3490 (27%)]\tTrain Loss: 0.180739\n",
            "Train Epoch 6: [1280/3490 (36%)]\tTrain Loss: 0.308393\n",
            "Train Epoch 6: [1600/3490 (45%)]\tTrain Loss: 0.184496\n",
            "Train Epoch 6: [1920/3490 (55%)]\tTrain Loss: 0.204810\n",
            "Train Epoch 6: [2240/3490 (64%)]\tTrain Loss: 0.288206\n",
            "Train Epoch 6: [2560/3490 (73%)]\tTrain Loss: 0.437824\n",
            "Train Epoch 6: [2880/3490 (82%)]\tTrain Loss: 0.283096\n",
            "Train Epoch 6: [3200/3490 (91%)]\tTrain Loss: 0.072660\n",
            "***********    TEST_ACC = 3.66%    ***********\n",
            "Train Epoch 7: [0/3490 (0%)]\tTrain Loss: 0.051999\n",
            "Train Epoch 7: [320/3490 (9%)]\tTrain Loss: 0.105167\n",
            "Train Epoch 7: [640/3490 (18%)]\tTrain Loss: 0.175677\n",
            "Train Epoch 7: [960/3490 (27%)]\tTrain Loss: 0.175105\n",
            "Train Epoch 7: [1280/3490 (36%)]\tTrain Loss: 0.198693\n",
            "Train Epoch 7: [1600/3490 (45%)]\tTrain Loss: 0.136584\n",
            "Train Epoch 7: [1920/3490 (55%)]\tTrain Loss: 0.192152\n",
            "Train Epoch 7: [2240/3490 (64%)]\tTrain Loss: 0.388696\n",
            "Train Epoch 7: [2560/3490 (73%)]\tTrain Loss: 0.161129\n",
            "Train Epoch 7: [2880/3490 (82%)]\tTrain Loss: 0.149411\n",
            "Train Epoch 7: [3200/3490 (91%)]\tTrain Loss: 0.267639\n",
            "Train Epoch 8: [0/3490 (0%)]\tTrain Loss: 0.137622\n",
            "Train Epoch 8: [320/3490 (9%)]\tTrain Loss: 0.294722\n",
            "Train Epoch 8: [640/3490 (18%)]\tTrain Loss: 0.356972\n",
            "Train Epoch 8: [960/3490 (27%)]\tTrain Loss: 0.191362\n",
            "Train Epoch 8: [1280/3490 (36%)]\tTrain Loss: 0.306167\n",
            "Train Epoch 8: [1600/3490 (45%)]\tTrain Loss: 0.157849\n",
            "Train Epoch 8: [1920/3490 (55%)]\tTrain Loss: 0.226944\n",
            "Train Epoch 8: [2240/3490 (64%)]\tTrain Loss: 0.387333\n",
            "Train Epoch 8: [2560/3490 (73%)]\tTrain Loss: 0.158189\n",
            "Train Epoch 8: [2880/3490 (82%)]\tTrain Loss: 0.578578\n",
            "Train Epoch 8: [3200/3490 (91%)]\tTrain Loss: 0.099368\n",
            "***********    TEST_ACC = 3.69%    ***********\n",
            "Train Epoch 9: [0/3490 (0%)]\tTrain Loss: 0.259577\n",
            "Train Epoch 9: [320/3490 (9%)]\tTrain Loss: 0.102388\n",
            "Train Epoch 9: [640/3490 (18%)]\tTrain Loss: 0.069194\n",
            "Train Epoch 9: [960/3490 (27%)]\tTrain Loss: 0.372818\n",
            "Train Epoch 9: [1280/3490 (36%)]\tTrain Loss: 0.570222\n",
            "Train Epoch 9: [1600/3490 (45%)]\tTrain Loss: 0.173517\n",
            "Train Epoch 9: [1920/3490 (55%)]\tTrain Loss: 0.332310\n",
            "Train Epoch 9: [2240/3490 (64%)]\tTrain Loss: 0.083688\n",
            "Train Epoch 9: [2560/3490 (73%)]\tTrain Loss: 0.271934\n",
            "Train Epoch 9: [2880/3490 (82%)]\tTrain Loss: 0.096809\n",
            "Train Epoch 9: [3200/3490 (91%)]\tTrain Loss: 0.144015\n",
            "Train Epoch 10: [0/3490 (0%)]\tTrain Loss: 0.109931\n",
            "Train Epoch 10: [320/3490 (9%)]\tTrain Loss: 0.365656\n",
            "Train Epoch 10: [640/3490 (18%)]\tTrain Loss: 0.151563\n",
            "Train Epoch 10: [960/3490 (27%)]\tTrain Loss: 0.284949\n",
            "Train Epoch 10: [1280/3490 (36%)]\tTrain Loss: 0.117305\n",
            "Train Epoch 10: [1600/3490 (45%)]\tTrain Loss: 0.073948\n",
            "Train Epoch 10: [1920/3490 (55%)]\tTrain Loss: 0.098463\n",
            "Train Epoch 10: [2240/3490 (64%)]\tTrain Loss: 0.280961\n",
            "Train Epoch 10: [2560/3490 (73%)]\tTrain Loss: 0.329604\n",
            "Train Epoch 10: [2880/3490 (82%)]\tTrain Loss: 0.181442\n",
            "Train Epoch 10: [3200/3490 (91%)]\tTrain Loss: 0.107080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load lại model đã train\n",
        "model.load_state_dict(torch.load(checkpoint))\n",
        "\n",
        "# Xem lại thông số của model\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5S5JSuoZZ-x",
        "outputId": "96c52356-56bd-4bac-d945-3fdb55727ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.8, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=5184, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbol_dict = {'0':'α',\n",
        "\t       '1':'β',\n",
        "\t\t   '2':'γ',\n",
        "\t\t   '3':'δ',\n",
        "\t\t   '4':'λ',\n",
        "\t\t   '5':'μ',\n",
        "\t\t   '6':'Ω',\n",
        "\t\t   '7':'π',\n",
        "\t\t   '8':'φ',\n",
        "\t\t\t'9':'θ'}"
      ],
      "metadata": {
        "id": "a51_fkBglQ-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra một batch trong tập test\n",
        "item = iter(test_loader)\n",
        "data, target = next(item)\n",
        "\n",
        "# Lấy random index của một phần tử trong batch đó\n",
        "test_idx = random.choice(range(len(data)))\n",
        "\n",
        "# Lấy một ví dụ trong tập test\n",
        "data = data[test_idx]\n",
        "target = target[test_idx]\n",
        "assert data.shape == (3, 25, 25)"
      ],
      "metadata": {
        "id": "LYr_eq3nZcZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sử dụng model đã train\n",
        "def plot(data, model):\n",
        "  data = torch.unsqueeze(data, dim=0) # unsqueeze data\n",
        "  data = data.to(device)\n",
        "  output = model(data)\n",
        "  output = F.log_softmax(output, dim=1) # log softmax, chú ý dim\n",
        "  pred = output.argmax(dim=1, keepdim=True) # argmax, chú ý keepdim, dim=1\n",
        "  print(\"Predict Number : \", symbol_dict[str(pred[0][0].detach().cpu().numpy())])\n",
        "  plt.imshow(data[0][0].detach().cpu().numpy(), cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ekGUw6PlZdb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra một batch trong tập test\n",
        "item = iter(test_loader)\n",
        "data, target = next(item)\n",
        "\n",
        "# Lấy random index của một phần tử trong batch đó\n",
        "test_idx = random.choice(range(len(data)))\n",
        "\n",
        "# Lấy một ví dụ trong tập test\n",
        "data = data[test_idx]\n",
        "target = target[test_idx]\n",
        "assert data.shape == (3, 25, 25)\n",
        "plot(data, model)"
      ],
      "metadata": {
        "id": "Z7t4nQ4eZer_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the PyTorch model from the .pth file\n",
        "model_1 = torch.load('model.pth')\n",
        "\n",
        "# Load the image and convert it to a grayscale numpy array\n",
        "img = Image.open(\"/content/1e1 (1).png\")\n",
        "img_array = np.array(img)\n",
        "img_array = img_array.astype(np.float32) /255.0\n",
        "img_array = torch.from_numpy(img_array)\n",
        "data = img_array.permute(2, 0, 1)"
      ],
      "metadata": {
        "id": "aab3rcHKzo5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(data, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "rx5k-kVe1llP",
        "outputId": "66e556e1-8bea-43de-ec9e-6f1140434239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict Number :  λ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}