{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KlEFYW-AW1YX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X = mnist['data']\n",
        "y = mnist['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "import torch\n",
        "\n",
        "X_train = torch.Tensor(np.array(X_train)).view(-1, 1, 28, 28)\n",
        "y_train = torch.LongTensor(np.array(y_train))\n",
        "X_test = torch.Tensor(np.array(X_test)).view(-1, 1, 28, 28)\n",
        "y_test = torch.LongTensor(np.array(y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIlWdoxzW3FK",
        "outputId": "71b300a8-1f06-47d5-f477-7f510f909d7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Convert numpy arrays to torch.Tensors\n",
        "X_train = torch.Tensor(X_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "X_test = torch.Tensor(X_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "udhV1CICbhma"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Số classes trong tập MNIST\n",
        "num_classes = 10 \n",
        "\n",
        "# Số epoch\n",
        "epochs = 1\n",
        "\n",
        "# Các tham số cần thiết trong quá trình training\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "display_step = 100\n",
        "\n",
        "# Model path\n",
        "checkpoint = 'model.pth'\n",
        "\n",
        "# device: cuda\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uE0ZZYWYufE",
        "outputId": "01da28e4-543f-4054-c018-679185babaf8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=11*11*64, out_features=128) \n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ### START CODE HEAR ≈ 18 lines\n",
        "        ## 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        ### END CODE HERE\n",
        "        return x"
      ],
      "metadata": {
        "id": "7CzEhWMEXI9U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model vào GPU\n",
        "model = Net().to(device)\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX8DtgLlXLN0",
        "outputId": "5efb57be-de57-4099-ab06-c9bfaca55bc0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             320\n",
            "              ReLU-2           [-1, 32, 26, 26]               0\n",
            "            Conv2d-3           [-1, 64, 24, 24]          18,496\n",
            "              ReLU-4           [-1, 64, 24, 24]               0\n",
            "            Conv2d-5           [-1, 64, 22, 22]          36,928\n",
            "              ReLU-6           [-1, 64, 22, 22]               0\n",
            "         MaxPool2d-7           [-1, 64, 11, 11]               0\n",
            "           Dropout-8           [-1, 64, 11, 11]               0\n",
            "           Flatten-9                 [-1, 7744]               0\n",
            "           Linear-10                  [-1, 128]         991,360\n",
            "             ReLU-11                  [-1, 128]               0\n",
            "           Linear-12                   [-1, 64]           8,256\n",
            "             ReLU-13                   [-1, 64]               0\n",
            "           Linear-14                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 1,056,010\n",
            "Trainable params: 1,056,010\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.55\n",
            "Params size (MB): 4.03\n",
            "Estimated Total Size (MB): 5.58\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropy\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Adam Optimizer set params=model.parameters(), lr=learning_rate\n",
        "best_val_loss = 999\n",
        "\n",
        "# Loop for each epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # Quá trình training \n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Clear gradients for this training step \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        # Backpropagation, compute gradients\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        # Apply gradients\n",
        "        optimizer.step()\n",
        "        if batch_idx % display_step == 0:\n",
        "            print('Train Epoch {}: [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "    # Quá trình testing \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    # Set no grad cho quá trình testing\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            output = F.log_softmax(output, dim=1) # Sử dụng hàm log_sotmax để tính xác suất cho output\n",
        "            test_loss += criterion(output, target) \n",
        "            pred = output.argmax(dim = 1, keepdim = True) # Sử dụng hàm argmax để lấy predicted label, chú ý: dim = 1, keepdim=True\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset) \n",
        "    if test_loss < best_val_loss:\n",
        "      best_val_loss = test_loss\n",
        "      torch.save(model.state_dict(), checkpoint)  # Lưu model path\n",
        "      print(\"***********    TEST_ACC = {:.2f}%    ***********\".format(correct/100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHm6WgrdZYUU",
        "outputId": "faa4dd55-77de-4989-ee17-311267c89630"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch 1: [0/56000 (0%)]\tTrain Loss: 2.769090\n",
            "Train Epoch 1: [3200/56000 (6%)]\tTrain Loss: 0.449475\n",
            "Train Epoch 1: [6400/56000 (11%)]\tTrain Loss: 0.160228\n",
            "Train Epoch 1: [9600/56000 (17%)]\tTrain Loss: 0.122669\n",
            "Train Epoch 1: [12800/56000 (23%)]\tTrain Loss: 0.004734\n",
            "Train Epoch 1: [16000/56000 (29%)]\tTrain Loss: 0.306578\n",
            "Train Epoch 1: [19200/56000 (34%)]\tTrain Loss: 0.182485\n",
            "Train Epoch 1: [22400/56000 (40%)]\tTrain Loss: 0.004591\n",
            "Train Epoch 1: [25600/56000 (46%)]\tTrain Loss: 0.149170\n",
            "Train Epoch 1: [28800/56000 (51%)]\tTrain Loss: 0.321630\n",
            "Train Epoch 1: [32000/56000 (57%)]\tTrain Loss: 0.042211\n",
            "Train Epoch 1: [35200/56000 (63%)]\tTrain Loss: 0.036035\n",
            "Train Epoch 1: [38400/56000 (69%)]\tTrain Loss: 0.083660\n",
            "Train Epoch 1: [41600/56000 (74%)]\tTrain Loss: 0.039616\n",
            "Train Epoch 1: [44800/56000 (80%)]\tTrain Loss: 0.285082\n",
            "Train Epoch 1: [48000/56000 (86%)]\tTrain Loss: 0.004530\n",
            "Train Epoch 1: [51200/56000 (91%)]\tTrain Loss: 0.004854\n",
            "Train Epoch 1: [54400/56000 (97%)]\tTrain Loss: 0.021043\n",
            "***********    TEST_ACC = 136.48%    ***********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load lại model đã train\n",
        "model.load_state_dict(torch.load(checkpoint))\n",
        "\n",
        "# Xem lại thông số của model \n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5S5JSuoZZ-x",
        "outputId": "5ebc9f30-243d-4104-acfe-a43c349033d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=7744, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra một batch trong tập test\n",
        "item = iter(test_loader)\n",
        "data, target = next(item)\n",
        "\n",
        "# Lấy random index của một phần tử trong batch đó\n",
        "test_idx = random.choice(range(len(data)))\n",
        "\n",
        "# Lấy một ví dụ trong tập test\n",
        "data = data[test_idx]\n",
        "target = target[test_idx]\n",
        "assert data.shape == (1, 28, 28)"
      ],
      "metadata": {
        "id": "LYr_eq3nZcZ1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sử dụng model đã train\n",
        "def plot(data, model):\n",
        "  data = torch.unsqueeze(data, dim=0) # unsqueeze data\n",
        "  data = data.to(device)\n",
        "  output = model(data)\n",
        "  output = F.log_softmax(output, dim=1) # log softmax, chú ý dim\n",
        "  pred = output.argmax(dim=1, keepdim=True) # argmax, chú ý keepdim, dim=1\n",
        "  print(\"Predict Number : \", pred[0][0].detach().cpu().numpy()) \n",
        "  plt.imshow(data[0][0].detach().cpu().numpy(), cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ekGUw6PlZdb3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(data, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Z7t4nQ4eZer_",
        "outputId": "9a113480-a37c-488b-855c-1f5d9696796b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict Number :  4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the PyTorch model from the .pth file\n",
        "model_1 = torch.load('model.pth')\n",
        "\n",
        "# Load the image and convert it to a grayscale numpy array\n",
        "img = Image.open(\"/content/gamma_93081.jpg\").convert(\"L\")\n",
        "img = img.resize((28, 28), Image.ANTIALIAS) \n",
        "img_array = np.array(img)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "img_array = img_array.astype(np.float32) /255.0\n",
        "\n",
        "# Convert the numpy array to a PyTorch tensor\n",
        "img_tensor = torch.from_numpy(img_array)\n",
        "\n",
        "# Reshape the PyTorch tensor to match the expected input shape of the model\n",
        "img_tensor = img_tensor.reshape((1, 1, 28, 28))\n",
        "\n",
        "# Make a using the PyTorch model\n",
        "with torch.no_grad():\n",
        "    output = model(img_tensor)\n",
        "    \n",
        "# Get the predicted digit by selecting the class with the highest output probability\n",
        "predicted_digit = torch.argmax(output).item()\n",
        "\n",
        "print(\"Predicted Digit:\", predicted_digit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqXZiBbMhGNR",
        "outputId": "85d0fc86-e20e-4b99-e701-53667f9a55fc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Digit: 4\n"
          ]
        }
      ]
    }
  ]
}